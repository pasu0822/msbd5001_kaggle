{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns={\"date\":\"datetime\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_date = [pd.to_datetime(\"2018-01-01 00:00:00\")]\n",
    "\n",
    "while(all_date[-1]!=pd.to_datetime(\"2018-12-31 23:00:00\")):\n",
    "    all_date.append(all_date[-1]+timedelta(hours=1))\n",
    "    \n",
    "train_2018 = pd.DataFrame({\"datetime\":all_date})\n",
    "\n",
    "train_2018 = train_2018.merge(train[train.datetime.dt.year==2018], on=\"datetime\", how=\"left\").sort_values(\"datetime\")\n",
    "\n",
    "train_2018 = train_2018[train.columns]\n",
    "# train_2018 = train[train.datetime.dt.year==2017].copy()\n",
    "# train_2018.datetime = train_2018.datetime.apply(lambda x: x.replace(year=2018))\n",
    "# train_2018 = train[train.datetime.dt.year==2018].merge(train_2018[[\"datetime\"]], on=\"datetime\", how=\"left\")\n",
    "\n",
    "\n",
    "# all_date = [pd.to_datetime(\"2018-01-01 00:00:00\")]\n",
    "\n",
    "# while(all_date[-1]!=pd.to_datetime(\"2018-12-31 23:00:00\")):\n",
    "#     all_date.append(all_date[-1]+timedelta(hours=1))\n",
    "    \n",
    "# train_2018_tmp = pd.DataFrame({\"datetime\":all_date})\n",
    "\n",
    "# train_2018 = train_2018_tmp.merge(train_2018, on=\"datetime\", how=\"left\").sort_values(\"datetime\")\n",
    "\n",
    "# train_2018 = train_2018[train.columns]\n",
    "\n",
    "\n",
    "\n",
    "train = pd.concat([train[train.datetime.dt.year==2017], train_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"date\"] = train.datetime.dt.strftime(\"%Y-%m-%d\")\n",
    "# train[\"date_f\"] = (train.datetime.dt.year - 2017)*365.25 + train.datetime.dt.month*365.25/12 + train.datetime.dt.day\n",
    "\n",
    "train[\"time\"] = train.datetime.dt.strftime(\"%H:%M:%S\")\n",
    "train[\"time_f\"] = (train.datetime.dt.hour*60*60 + train.datetime.dt.minute*60 + train.datetime.dt.second)/(24*60*60)\n",
    "\n",
    "# train[\"datetime_f\"] = train.date_f + train.time_f\n",
    "\n",
    "train[\"dweek\"] = train.datetime.dt.dayofweek\n",
    "train[\"dweek_time\"] = train.dweek + train.time_f\n",
    "\n",
    "train[\"week\"] = train.datetime.dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2017 = train[train.datetime.dt.year==2017].copy()\n",
    "train_2018 = train[train.datetime.dt.year==2018].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookup Table adjusted by day min-max then closest template difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train = train_2018.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = train_train.groupby([\"dweek\",\"time\"]).speed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_day_mean = train_train.groupby(\"dweek\").speed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_day_min_max = train_train.groupby(\"dweek\").speed.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_ref_src = template2.reset_index()\n",
    "template_ref_src[\"prev\"] = template_ref_src.speed.shift(1).fillna(float(\"inf\"))\n",
    "template_ref_src[\"next\"] = template_ref_src.speed.shift(-1).fillna(float(\"inf\"))\n",
    "\n",
    "template_ref_src[\"ref\"] = template_ref_src.apply(lambda x: \"prev\" if abs(x.prev-x.speed) < abs(x.next-x.speed) else \"next\", axis=1)\n",
    "template_ref_src[\"ignoreOther\"] = template_ref_src.apply(lambda x: (abs(x[\"next\" if x.ref==\"prev\" else \"prev\"]-x.speed)/abs(x[x.ref]-x.speed) > 4), axis=1)\n",
    "\n",
    "template_ref = template_ref_src.set_index([\"dweek\",\"time\"]).ref\n",
    "template_ignore = template_ref_src.set_index([\"dweek\",\"time\"]).ignoreOther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(x, inputDF=train_2018):\n",
    "    day_min_max = inputDF[(inputDF.week==x.week)&(inputDF.dweek==x.dweek)&(inputDF.time!=x.time)].speed.std()\n",
    "    day_mean = inputDF[(inputDF.week==x.week)&(inputDF.dweek==x.dweek)&(inputDF.time!=x.time)].speed.mean()\n",
    "    return ((template2.loc[x.dweek, x.time] - template_day_mean.loc[x.dweek])*day_min_max/template_day_min_max.loc[x.dweek]) + day_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_2018.copy()\n",
    "\n",
    "tmp[\"computed\"] = tmp.apply(lambda x: lookup(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"diff\"] = tmp.speed - tmp.computed\n",
    "\n",
    "tmp[\"prev\"] = tmp[\"diff\"].fillna(method=\"ffill\").shift(1)\n",
    "tmp[\"next\"] = tmp[\"diff\"].fillna(method=\"bfill\").shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup2(x):\n",
    "    return x.computed + (((0 if np.isnan(x.prev) else x.prev) + (0 if np.isnan(x.next) else x.next))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "for i in range(7):\n",
    "    print(i)\n",
    "    error[i] = {}\n",
    "    result = tmp.copy()\n",
    "#     result[\"computed3\"] = result.apply(lookup2, axis=1)\n",
    "    \n",
    "    for j in range(0,30):#np.arange(1.99,3,0.01):\n",
    "        if(j==0):\n",
    "            result[\"computed3\"] = result.apply(lookup2, axis=1)\n",
    "            result[\"computed3_l\"] = result[\"computed3\"].copy()\n",
    "            result[\"computed3_r\"] = result[\"computed3\"].copy()\n",
    "        else:\n",
    "            result[\"computed3\"] = result.computed3.rolling(window=3, center=True).mean().fillna(result.computed3)\n",
    "            result[\"computed3_l\"] = result.computed3_l.rolling(window=3).mean().fillna(result.computed3_l)\n",
    "            result.sort_values(\"datetime\", ascending=False, inplace=True)\n",
    "            result[\"computed3_r\"] = result.computed3_r.rolling(window=3).mean().fillna(result.computed3_r)\n",
    "            result.sort_values(\"datetime\", ascending=True, inplace=True)\n",
    "            \n",
    "\n",
    "    #     result[\"computed3\"] = result.computed2.rolling(window=3, win_type=\"gaussian\", center=True).mean(std=j).fillna(result.computed2)\n",
    "        for k in tmp.time.unique():\n",
    "            mse_c = mean_squared_error(result[(result.dweek==i)&(result.time==k)&(result.speed.notna())].sort_values(\"id\").speed, result[(result.dweek==i)&(result.time==k)&(result.speed.notna())].sort_values(\"id\").computed3)\n",
    "            mse_l = mean_squared_error(result[(result.dweek==i)&(result.time==k)&(result.speed.notna())].sort_values(\"id\").speed, result[(result.dweek==i)&(result.time==k)&(result.speed.notna())].sort_values(\"id\").computed3_l)\n",
    "            mse_r = mean_squared_error(result[(result.dweek==i)&(result.time==k)&(result.speed.notna())].sort_values(\"id\").speed, result[(result.dweek==i)&(result.time==k)&(result.speed.notna())].sort_values(\"id\").computed3_r)\n",
    "            \n",
    "            if((mse_c<=mse_l)and(mse_c<=mse_r)):\n",
    "                mse = mse_c\n",
    "                direction = \"c\"\n",
    "            elif((mse_l<=mse_c)and(mse_l<=mse_r)):\n",
    "                mse = mse_l\n",
    "                direction = \"l\"\n",
    "            elif((mse_r<=mse_c)and(mse_r<=mse_l)):\n",
    "                mse = mse_r\n",
    "                direction = \"r\"\n",
    "            else:\n",
    "                mse = None\n",
    "                direction = None\n",
    "            \n",
    "            if(k not in error[i].keys()):\n",
    "                error[i][k] = (round(j,2), mse, direction, None)\n",
    "            elif(mse<error[i][k][1]):\n",
    "                error[i][k] = (round(j,2), mse, direction, False)\n",
    "            elif((mse>error[i][k][1]) and (error[i][k][3]==False)):\n",
    "                error[i][k] = (error[i][k][0], error[i][k][1], error[i][k][2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_smooth = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_cnt = list(pd.Series([optimal_smooth[i][j][0] for j in tmp.time.unique() for i in range(7)]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "result = tmp.copy()\n",
    "\n",
    "result[\"computed_0\"] = result.apply(lookup2, axis=1)\n",
    "\n",
    "computed_tmp_c = result[\"computed_0\"].copy()\n",
    "computed_tmp_l = result[\"computed_0\"].copy()\n",
    "computed_tmp_r = result[\"computed_0\"].copy()\n",
    "for i in range(1,max(smooth_cnt)+1):\n",
    "    computed_tmp_c = computed_tmp_c.rolling(window=3, center=True).mean().fillna(computed_tmp_c)\n",
    "    computed_tmp_l = computed_tmp_l.rolling(window=3).mean().fillna(computed_tmp_l)\n",
    "    computed_tmp_r = computed_tmp_r.iloc[::-1].rolling(window=3).mean().fillna(computed_tmp_r.iloc[::-1]).iloc[::-1]\n",
    "    if(i in smooth_cnt):\n",
    "        result[\"computed_c\" + str(i)] = computed_tmp_c.copy()\n",
    "        result[\"computed_l\" + str(i)] = computed_tmp_l.copy()\n",
    "        result[\"computed_r\" + str(i)] = computed_tmp_r.copy()\n",
    "result[\"computed4\"] = result.apply(lambda x: x[\"computed_\" + (str(optimal_smooth[x.dweek][x.time][2]) if (optimal_smooth[x.dweek][x.time][0]!=0) else \"\") + str(optimal_smooth[x.dweek][x.time][0])] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.395514104239702"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_2018\n",
    "mean_squared_error(result[result.speed.notna()].speed, result[result.speed.notna()].computed4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.merge(result[[\"datetime\",\"computed4\"]], left_on=\"date\",right_on=\"datetime\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.drop(columns=[\"date\",\"datetime\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.rename(columns={\"computed4\":\"speed\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"20340468.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
